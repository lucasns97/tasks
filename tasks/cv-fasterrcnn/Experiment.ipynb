{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast RCNN for object detection\n",
    "Este notebook apresenta:\n",
    "- como usar o [SDK](https://platiagro.github.io/sdk/) para carregar datasets, salvar modelos e outros artefatos.\n",
    "- como declarar parâmetros e usá-los para criar componentes reutilizáveis.\n",
    "\n",
    "\n",
    "**Este Notebook seguirá os seguintes tutoriais:**\n",
    "- Faster RCNN Train  <br>\n",
    "https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-train <br>\n",
    "- Faster RCNN Inference <br>\n",
    "https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-inference <br>\n",
    "- Faster RCNN Metric + scrpit details <br>\n",
    "https://www.kaggle.com/pestipeti/competition-metric-details-script <br>\n",
    "- TORCHVISION OBJECT DETECTION FINETUNING TUTORIAL <br>\n",
    "https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html <br>\n",
    "- TRANSFER LEARNING FOR COMPUTER VISION TUTORIAL <br>\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#transfer-learning-for-computer-vision-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parâmetros e hiperparâmetros para o modelo\n",
    "Os componentes podem declarar (e usar) estes parâmetros como padrão:\n",
    "- dataset\n",
    "- target\n",
    "\n",
    "Use estes parâmetros para carregar/salvar conjutos de dados, modelos, métricas e figuras com a ajuda do [SDK da PlatIAgro](https://platiagro.github.io/sdk/). <br>\n",
    "É possível também declarar parâmetros personalizados para serem definidos ao executar um experimento. \n",
    "\n",
    "Selecione os hiperparâmetros e seus respectivos valores para serem usados ao treinar o modelo:\n",
    "- language\n",
    "\n",
    "Estes parâmetros são alguns dos oferecidos pela classe do modelo, você também pode utilizar outros existentes. <br>\n",
    "Dê uma olhada nos [parâmetros do modelo](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn-impute-simpleimputer) para mais informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parâmetros\n",
    "dataset = \"\" #@param {type:\"string\"}\n",
    "target = \"sentiment\" #@param {type:\"string\", label:\"Atributo alvo\", description:\"Seu modelo será treinado para prever os valores do alvo.\"}\n",
    "#Hyperparâametros\n",
    "train_batch_size = 2 #@param {type:\"integer\", label:\"Tamanho da carga de treino\", description:\"Tamanho da carga de dados que será utilizada durante o treinamento.\"}\n",
    "valid_batch_size = 4 #@param {type:\"integer\", label:\"Tamanho da carga de validação\", description:\"Tamanho da carga de dados que será utilizada durante o validação.\"}\n",
    "test_batch_size = 2 #@param {type:\"integer\", label:\"Tamanho da carga de teste\", description:\"Tamanho da carga de dados que será utilizada durante o teste.\"}\n",
    "max_epochs = 2 #@param {type:\"integer\", label:\"Quantidade máquina de épocas\", description:\"Quantidade de épocas para o treinamento.\"}\n",
    "learning_rate = 0.005 #@param {type:\"number\", label:\"Taxa de aprendizado\", description:\"Taxa de aprendizado utilizada pelo modelo.\"}\n",
    "momentum = 0.9 #@param {type:\"number\", label:\"Momentum\", description:\"Momentum utilizado pelo otimizador do modelo.\"}\n",
    "weight_decay = 0.0005 #@param {type:\"number\", label:\"Taxa de queda do peso\", description:\"Taxa de queda do peso utilizado durante o treinamento.\"}\n",
    "num_classes = 2 #@param {type:\"integer\", label:\"Quantidade de classes\", description:\"Quantidade de classes.\"}\n",
    "detection_threshold = 0.5 #@param {type:\"number\", label:\"Limiar de detecção\", description:\"Limiar de detecção.\"}\n",
    "seed = 7 #@param {type:\"integer\", label:\"Semente\", description:\"Semente para inicializar geradores de números aleatórios.\"}\n",
    "\n",
    "# selected features to perform the model\n",
    "coord_format = \"coco\" #@param [\"coco\",\"pascal_voc\"]  {type:\"string\", label:\"Classes do modelo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# ADD FILES PY DOWNLOAD\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração dos dados do arquivo .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = dataset.split('.')[0]\n",
    "\n",
    "!mkdir -p {folder}\n",
    "!unzip -o {dataset} -d {folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "images = os.listdir(f'{folder}')\n",
    "\n",
    "images = [x for x in images if not x.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifica a existência de GPU\n",
    "import torch\n",
    "\n",
    "dev = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure quantidade de mensagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.getLogger(\"transformers.configuration_utils\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"lightning\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixa semente de pesos aleatórios para replicabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso ao conjunto de dados\n",
    "\n",
    "O conjunto de dados utilizado nesta etapa será o mesmo carregado através da plataforma.<br>\n",
    "O tipo da variável retornada depende do arquivo de origem:\n",
    "- [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) para CSV e compressed CSV: .csv .csv.zip .csv.gz .csv.bz2 .csv.xz\n",
    "- [Binary IO stream](https://docs.python.org/3/library/io.html#binary-i-o) para outros tipos de arquivo: .jpg .wav .zip .h5 .parquet etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(f'{folder}/train.csv')\n",
    "test_df = pd.read_csv(f'{folder}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "train_df[['x', 'y', 'w', 'h']] = -1\n",
    "\n",
    "def expand_bbox(x):\n",
    "    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n",
    "    if len(r) == 0:\n",
    "        r = [-1, -1, -1, -1]\n",
    "    return r\n",
    "\n",
    "train_df[['x', 'y', 'w', 'h']] = np.stack(train_df['bbox'].apply(lambda x: expand_bbox(x)))\n",
    "train_df.drop(columns=['bbox'], inplace=True)\n",
    "train_df[['x', 'y', 'w', 'h']] = train_df[['x', 'y', 'w', 'h']].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = train_df['image_id'].unique()\n",
    "valid_ids = image_ids[-665:]\n",
    "train_ids = image_ids[:-665]\n",
    "valid_df = train_df[train_df['image_id'].isin(valid_ids)]\n",
    "train_df = train_df[train_df['image_id'].isin(train_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações com Albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "def get_debug_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import WheatDataset\n",
    "\n",
    "ds_debug = WheatDataset(train_df, DIR_TRAIN, get_debug_transform())\n",
    "image, target, image_id = ds_debug[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collate para colocar batch em tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "debug_loader = DataLoader(\n",
    "    ds_debug,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=cpu_count(),\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando um exemplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## colocar if para verificar se tem dado de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, image_ids,targets = next(iter(debug_loader)) \n",
    "images = list(image.to(device) for image in images) \n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = targets[2]['boxes'].cpu().numpy().astype(np.int32)\n",
    "sample = images[2].permute(1,2,0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(sample,\n",
    "                  (box[0], box[1]),\n",
    "                  (box[2], box[3]),\n",
    "                  (220, 0, 0), 3)\n",
    "    \n",
    "ax.set_axis_off()\n",
    "ax.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parâmetros do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [train_df,valid_df,test_df]\n",
    "\n",
    "hyperparams = {'learning_rate':learning_rate,\n",
    "               'momentum':momentum,\n",
    "               'weight_decay':weight_decay,\n",
    "               'detection_threshold':detection_threshold,\n",
    "               'train_batch_size':train_batch_size,\n",
    "               'valid_batch_size':valid_batch_size,\n",
    "               'test_batch_size':test_batch_size\n",
    "              }\n",
    "\n",
    "model_parameters = {'num_classes': num_classes,\n",
    "                    'coord_format':coord_format\n",
    "                   }\n",
    "\n",
    "dataset_infos = {'all_data':all_data,\n",
    "                 'CustomDataset':WheatDataset,\n",
    "                 'DIR_TRAIN':DIR_TRAIN,\n",
    "                 'DIR_TEST':DIR_TEST\n",
    "                }\n",
    "\n",
    "extra_infos = {'overfit': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Finetuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrcnn_finetuner import FastRCNNFinetuner\n",
    "\n",
    "model = FastRCNNFinetuner(hyperparams=hyperparams,\n",
    "                       model_parameters=model_parameters,\n",
    "                       dataset_infos=dataset_infos,\n",
    "                       extra_infos=extra_infos)\n",
    "\n",
    "sum([torch.tensor(x.size()).prod() for x in model.parameters() if x.requires_grad]) # trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(gpus=0, \n",
    "                     checkpoint_callback=False,  # Disable checkpoint saving.\n",
    "                     fast_dev_run=True)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando ou treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     max_epochs=2,\n",
    "                     check_val_every_n_epoch=1,\n",
    "                     profiler=True,\n",
    "                     progress_bar_refresh_rate=1)\n",
    "\n",
    "model = FastRCNNFinetuner(hyperparams=hyperparams,\n",
    "                       model_parameters=model_parameters,\n",
    "                       dataset_infos=dataset_infos,\n",
    "                       extra_infos = extra_infos) \n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva figuras\n",
    "\n",
    "Utiliza a função `save_figures` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar figuras do [matplotlib](https://matplotlib.org/3.2.1/gallery/index.html). <br>\n",
    "\n",
    "A avaliação do desempenho do modelo pode ser feita por meio da análise da [Curva ROC (ROC)](https://pt.wikipedia.org/wiki/Caracter%C3%ADstica_de_Opera%C3%A7%C3%A3o_do_Receptor).  Esse gráfico permite avaliar a performance de um classificador binário para diferentes pontos de cortes. A métrica [AUC (Area under curve)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve) também é calculada e indicada na legenda do gráfico.<br>\n",
    "Se a variável resposta tiver mais de duas categorias, o cálculo da curva ROC e AUC é feito utilizando o algoritmo [one-vs-rest](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics), ou seja, calcula-se a curva ROC e AUC de cada classe em relação ao restante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots\n",
    "\n",
    "overlaping_multiple_plots(2, 2, model.result_valid)\n",
    "inference_multiple_plots(2, 2, model.result_test)\n",
    "\n",
    "if not weights_retrieved:\n",
    "\n",
    "    performance_loss_visualization(model.df_performance_train_batch['train_batch_loss'].to_numpy(), epoch_or_batch=\"Batch\",step = \"Train\")\n",
    "    performance_loss_visualization(model.df_performance_train_epoch['train_epoch_loss'].to_numpy(), epoch_or_batch=\"Epoch\",step = \"Train\")\n",
    "    performance_loss_iou_visualization(model.df_performance_valid_batch['valid_batch_loss'].to_numpy(), model.df_performance_valid_batch['valid_batch_iou'].to_numpy(),epoch_or_batch=\"Batch\",step = \"Valid\")\n",
    "    performance_loss_iou_visualization(model.df_performance_valid_epoch['valid_epoch_loss'].to_numpy(), model.df_performance_valid_epoch['valid_epoch_iou'].to_numpy(),epoch_or_batch=\"Epoch\",step = \"Valid\")\n",
    "    performance_iou_visualization(model.df_performance_test_batch['test_batch_iou'].to_numpy(), epoch_or_batch=\"Batch\",step = \"Test\")\n",
    "    performance_iou_visualization(model.df_performance_test_epoch['test_epoch_iou'].to_numpy(), epoch_or_batch=\"Epoch\",step = \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salva modelo e outros artefatos\n",
    "\n",
    "Utiliza a função `save_model` do [SDK da PlatIAgro](https://platiagro.github.io/sdk/) para salvar modelos e outros artefatos.<br>\n",
    "Essa função torna estes artefatos disponíveis para o notebook de implantação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pytorch_model.pt'\n",
    "\n",
    "torch.save(model.state_dict(), f'/tmp/data/{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dataset_infos = {'all_data':all_data}\n",
    "\n",
    "deployment_infos = {'columns':columns,\n",
    "                    'X_test':X_test\n",
    "                   }\n",
    "\n",
    "artifacts = {'hyperparams':hyperparams,\n",
    "             'model_parameters':model_parameters,\n",
    "             'dataset_infos':dataset_infos,\n",
    "             'extra_infos':extra_infos,\n",
    "             'deployment_infos':deployment_infos\n",
    "            }\n",
    "\n",
    "dump(artifacts, \"/tmp/data/fasterrcnn.joblib\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
