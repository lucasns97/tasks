{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   MTCNN Face Detection - Implantação\n",
    "\n",
    "*   Este componente utiliza a biblioteca [facenet-pytorch](https://github.com/timesler/facenet-pytorch), a qual disponibiliza o algorítimo [MTCNN](https://arxiv.org/abs/1604.02878). \n",
    "\n",
    "* O MTCNN possui a performance estado da arte nos benchmarks [FDDB](http://vis-www.cs.umass.edu/fddb/) e [WIDER FACE](http://shuoyang1213.me/WIDERFACE/)\n",
    "\n",
    "*   Melhores explicações são encontradas neste [artigo do kaggle](https://www.kaggle.com/timesler/guide-to-mtcnn-in-facenet-pytorch)\n",
    "\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install facenet-pytorch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Model.py\n",
    "import joblib\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import cv2\n",
    "from mtcnn import MTCNN_Model\n",
    "\n",
    "        \n",
    "class Model(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        artifacts = joblib.load(\"/tmp/data/mtcnn.joblib\")\n",
    "        self.model_parameters = artifacts[\"model_parameters\"]\n",
    "        self.inference_parameters = artifacts[\"inference_parameters\"]\n",
    "        \n",
    "    def class_names(self):\n",
    "        \n",
    "        return ['bboxcoord1', 'bboxcoord2', 'bboxcoord3', 'bboxcoord4', 'probability']\n",
    "        \n",
    "    def format_result(self, boxes, probs):\n",
    "        \n",
    "        res = []\n",
    "        \n",
    "        for i in range(len(boxes)):\n",
    "            \n",
    "            bbox = list(map(float, boxes[i]))\n",
    "            bbox.extend([float(probs[i])])\n",
    "            res.append(bbox)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def predict(self, X, feature_names, meta=None):\n",
    "\n",
    "        #im_bytes = base64.b64decode(X[0])\n",
    "        im_bytes = base64.b64decode(X[0,0])\n",
    "        im_arr = np.frombuffer(im_bytes, dtype=np.uint8)\n",
    "        img = cv2.imdecode(im_arr, flags=cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        model = MTCNN_Model(self.model_parameters, self.inference_parameters)\n",
    "        boxes, probs = model.predict(img, \"Deployment\")\n",
    "        result = self.format_result(boxes, probs)\n",
    "        \n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "experiment_id": "bc50b220-78cf-4cb7-8f63-04b3a313dd6c",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "operator_id": "bfa59444-81b5-4182-850b-d38b6931cfc5",
  "task_id": "e60f2709-5661-4ae3-8ad7-ec895daf95f6"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
