{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador de sentenças utilizando GloVe embeddings bag - Implantação\n",
    "\n",
    "Este componente é um classificador sentenças multiclasse baseado nos pacotes de Embeddings GloVe disponiblizado pela [Stanford](https://nlp.stanford.edu/projects/glove/) para a lngua inglesa e pelo [NILC-São Carlos](http://nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc) para a língua portuguesa.\n",
    "\n",
    "### **Em caso de dúvidas, consulte os [tutoriais da PlatIAgro](https://platiagro.github.io/tutorials/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaração de Classe para Predições em Tempo Real\n",
    "\n",
    "A tarefa de implantação cria um serviço REST para predições em tempo-real.<br>\n",
    "Para isso você deve criar uma classe `Model` que implementa o método `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-27 12:20:14--  https://raw.githubusercontent.com/platiagro/tasks/main/tasks/nlp-glove-embeddings-sentence-classification/dataset.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.64.133, 151.101.192.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.64.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 744 [text/plain]\n",
      "Saving to: ‘dataset.py.17’\n",
      "\n",
      "dataset.py.17       100%[===================>]     744  --.-KB/s    in 0s      \n",
      "\n",
      "2021-01-27 12:20:14 (49.1 MB/s) - ‘dataset.py.17’ saved [744/744]\n",
      "\n",
      "--2021-01-27 12:20:15--  https://raw.githubusercontent.com/platiagro/tasks/main/tasks/nlp-glove-embeddings-sentence-classification/glove_embeddings.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.64.133, 151.101.192.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.64.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3103 (3.0K) [text/plain]\n",
      "Saving to: ‘glove_embeddings.py.18’\n",
      "\n",
      "glove_embeddings.py 100%[===================>]   3.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-01-27 12:20:15 (61.7 MB/s) - ‘glove_embeddings.py.18’ saved [3103/3103]\n",
      "\n",
      "--2021-01-27 12:20:16--  https://raw.githubusercontent.com/platiagro/tasks/main/tasks/nlp-glove-embeddings-sentence-classification/model_lightning.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.64.133, 151.101.0.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.64.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15908 (16K) [text/plain]\n",
      "Saving to: ‘model_lightning.py.16’\n",
      "\n",
      "model_lightning.py. 100%[===================>]  15.54K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2021-01-27 12:20:16 (6.90 MB/s) - ‘model_lightning.py.16’ saved [15908/15908]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/platiagro/tasks/main/tasks/nlp-glove-embeddings-sentence-classification/dataset.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/main/tasks/nlp-glove-embeddings-sentence-classification/glove_embeddings.py\n",
    "!wget https://raw.githubusercontent.com/platiagro/tasks/main/tasks/nlp-glove-embeddings-sentence-classification/model_lightning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Model.py\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "from typing import Dict, Iterable, List, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from dataset import MyDataset\n",
    "from model_lightning import GloveFinetuner\n",
    "from glove_embeddings import GloveEmbeddings\n",
    "from platiagro import load_model\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, dataset: str = None, target: str = None):\n",
    "        \n",
    "        # Carrega artefatos: estimador, etc\n",
    "        artifacts_file_name = \"artifacts.p\"\n",
    "        artifacts = pickle.load(open(f\"/tmp/data/{artifacts_file_name}\", \"rb\"))\n",
    "        \n",
    "        self.hyperparams = artifacts[\"hyperparams\"]\n",
    "        self.model_parameters = artifacts[\"model_parameters\"]\n",
    "        self.dataset_infos = artifacts[\"dataset_infos\"]\n",
    "        self.extra_infos = artifacts[\"extra_infos\"]\n",
    "        self.deployment_infos = artifacts[\"deployment_infos\"]\n",
    "        self.lightning_configs = artifacts[\"lightning_configs\"]  \n",
    "        \n",
    "        # Carregando classe GloveEmbeddings\n",
    "        self.glove_embeddings = self.load_class_glove_embeddings()\n",
    "\n",
    "        # Carregando pesos do modelo\n",
    "        self.model = self.load_model()\n",
    "\n",
    "        #Colocando modelo em modo de avaliação para fazer predições\n",
    "        self.model.eval()\n",
    "\n",
    "    def load_model(self):\n",
    "        \n",
    "        dataset_infos = {\n",
    "            \"all_data\": self.dataset_infos[\"all_data\"],\n",
    "            \"CustomDataset\": MyDataset,\n",
    "        }\n",
    "        model = GloveFinetuner.load_from_checkpoint(\n",
    "            checkpoint_path= self.deployment_infos[\"checkpoint_path\"],\n",
    "            hyperparams=self.hyperparams,\n",
    "            model_parameters=self.model_parameters,\n",
    "            dataset_infos=dataset_infos,\n",
    "            extra_infos=self.extra_infos,\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def load_class_glove_embeddings(self):\n",
    "        \n",
    "        glove_embeddings = GloveEmbeddings(\n",
    "            glove_dim = self.deployment_infos[\"glove_dim\"],\n",
    "            glove_weights_file_name = self.deployment_infos[\"glove_weights_file_name\"],\n",
    "            device = self.deployment_infos[\"device\"]\n",
    "        )\n",
    "        \n",
    "        return glove_embeddings\n",
    "\n",
    "    def predict(\n",
    "        self, X: np.ndarray, feature_names: Iterable[str], meta: Dict = None\n",
    "    ) -> Union[np.ndarray, List, str, bytes]:\n",
    "        if feature_names:\n",
    "            # Antes de utilizar o conjunto de dados X no modelo, reordena suas features de acordo com a ordem utilizada no treinamento\n",
    "            df = pd.DataFrame(X, columns=feature_names)\n",
    "            X = df[self.deployment_infos[\"columns\"]].to_numpy()\n",
    "        \n",
    "        X_inference_glove_ids, X_inference_glove_words = self.glove_embeddings.build_glove_matrix(X)\n",
    "        result = self.model.predict(X_inference_glove_ids, X_inference_glove_words)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:loading projection weights from ./glove_s300_ingles.txt\n",
      "INFO:gensim.models.keyedvectors:loading projection weights from ./glove_s300_ingles.txt\n"
     ]
    }
   ],
   "source": [
    "from Model import Model\n",
    "\n",
    "inferenceModel = Model()\n",
    "X_test = inferenceModel.deployment_infos[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(\n",
    "    [[\"Un-bleeping-believable! Meg Ryan doesn't even look her usual ,pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = inferenceModel.predict(X_test, None)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "experiment_id": "e28df18f-9c28-489c-a06d-b8f6b41d2b86",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "operator_id": "a0e7602d-bd2e-4aec-81a1-7c40a39a6d9d",
  "task_id": "ba190196-8c85-4d91-a249-6a0b288f01dc"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}